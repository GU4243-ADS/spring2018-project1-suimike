---
title: "Who's the Scariest of Them All?"
author: "Michael Sheng"
date: "January 22, 2018"
output:
  pdf_document: default
  html_document: default
---

# Add Libraries

```{r, message = F, warning = F}
packages.used <- c("ggplot2", "dplyr", "tidytext", "wordcloud", "stringr", "ggridges")

# check packages that need to be installed.
packages.needed <- setdiff(packages.used, intersect(installed.packages()[,1], packages.used))

# install additional packages
if(length(packages.needed) > 0) {
  install.packages(packages.needed, dependencies = TRUE, repos = 'http://cran.us.r-project.org')
}

library(ggplot2)
library(dplyr)
library(tidytext)
library(wordcloud)
library(stringr)
library(ggridges)
```

## Read in the data
The following code assumes that the dataset `spooky.csv` lives in a `data` folder (and that we are inside a `docs` folder).

```{r, message = F, warning = F}
spooky <- read.csv('../data/spooky.csv', as.is = TRUE)
```

### Data Cleaning
-from sample
We first use the `unnest_tokens()` function to drop all punctuation and transform all words into lower case.  At least for now, the punctuation isn't really important to our analysis -- we want to study the words.  In addition, `tidytext` contains a dictionary of stop words, like "and" or "next", that we will get rid of for our analysis, the idea being that the non-common words (...maybe the SPOOKY words) that the authors use will be more interesting.
http://environmentalcomputing.net/plotting-with-ggplot-adding-titles-and-axis-names/

```{r, message = F, warning = F}
spooky_wrd <- unnest_tokens(spooky, word, text)
spooky_wrd <- anti_join(spooky_wrd, stop_words, by = "word")

```

### Data Visualization
-from sample
First we'll do some simple numerical summaries of the data to provide some nice visualizations.

```{r, message = F, warning = F}
p1 <- ggplot(spooky) +
      geom_bar(aes(author, fill = author)) +
      theme(legend.position = "none")
spooky
spooky$sen_length <- str_length(spooky$text)
head(spooky$sen_length)


p2 <- ggplot(spooky) +
      geom_density_ridges(aes(sen_length, author, fill = author)) +
      scale_x_log10() + 
      theme(legend.position = "none") +
      labs(x = "Sentence length [# characters]")

spooky_wrd$word_length <- str_length(spooky_wrd$word)
head(spooky_wrd$word_length)

p3 <- ggplot(spooky_wrd) +
      geom_density(aes(word_length, fill = author), bw = 0.05, alpha = 0.3) +
      scale_x_log10() +
      theme(legend.position = "none") +
      labs(x = "Word length [# characters]")

layout <- matrix(c(1, 2, 1, 3), 2, 2, byrow = TRUE)

png('../figs/multiplot.png')
multiplot(p1, p2, p3, layout = layout)
dev.off()
```

### Sentiment Analysis
We want to examine the sentiment of the author's writings through a sentiment score and how much the emotion of fear is evoked in the book based on frequency. These are horror authors after all; who's the scariest of them all?

Procedures borrowed from https://www.tidytextmining.com/sentiment.html

We load both a numeric sentiment library 'afinn' and descriptive emotion sentiment library 'nrc' from the tidytext library.

For each author, we add the numeric sentiments of each book, and divide by the total number of words, to get a polarity score (negative/positive).

We also match words from 'nrc' for fear from each author (to graph by frequency)

```{r sentiment analysis, message = F, warning = F}

senti_afinn <- data.frame(get_sentiments("afinn"))
senti_nrc <- data.frame(get_sentiments("nrc"))

#sum sentiment for each author
afinn_score <- spooky_wrd %>% inner_join(senti_afinn,by="word")

#get total number of words for each author (to normalize a metric)
author_word_freq <- afinn_score %>% group_by(author) %>% summarise(num_rows = length(author))

#calculate metric
author_polarity <- author_word_freq %>% inner_join(aggregate(score~author,afinn_score,sum))%>% mutate(polarity = score/num_rows)

nrcfear <- filter(senti_nrc,senti_nrc$sentiment == 'fear')

#get a sorted list of most common fear words for each author
fear_words_EAP <- spooky_wrd %>% filter(author == "EAP") %>% inner_join(nrcfear) %>% count(word,sort=TRUE)
fear_words_HPL <- spooky_wrd %>% filter(author == "HPL") %>% inner_join(nrcfear) %>% count(word,sort=TRUE)
fear_words_MWS <- spooky_wrd %>% filter(author == "MWS") %>% inner_join(nrcfear) %>% count(word,sort=TRUE)

```

#plotting

```{r plot, message = F, warning = F}

png('../figs/polarity.png')
barplot(author_polarity$polarity,main = "Negativity Per Word", names.arg=author_polarity$author)
dev.off()
plot_fear_words <- function(fear_words,auth)
{
  fear_words %>% top_n(10) %>%  ungroup() %>%
  mutate(word = reorder(word, n)) %>% ggplot(aes(word, n, fill = "red")) + ggtitle(paste(auth,"'Fear' Words",sep=" ")) +
  geom_col(show.legend = FALSE) +
  labs(y = "Frequency",
       x = NULL) +
  coord_flip()
}
png('../figs/EAP.png')
plot_fear_words(fear_words_EAP,"EAP")
dev.off()
png('../figs/HPL.png')
plot_fear_words(fear_words_HPL,"HPL")
dev.off()
png('../figs/MWS.png')
plot_fear_words(fear_words_MWS,"MWS")
dev.off()
```
